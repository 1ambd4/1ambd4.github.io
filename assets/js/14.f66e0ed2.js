(window.webpackJsonp=window.webpackJsonp||[]).push([[14],Array(405).concat([function(t,a,s){t.exports=s.p+"assets/img/lec8_which_statement_can_affect_pointer_in_java.553a25f6.png"},,,,,,,,,,,,,,,,,,,,,,,,,,,,,,function(t,a,s){t.exports=s.p+"assets/img/lec2_compiler_process.f343b260.png"},function(t,a,s){t.exports=s.p+"assets/img/lec2_how_to_build_basic_blocks.7e4e2386.png"},function(t,a,s){t.exports=s.p+"assets/img/lec2_example_of_build_basic_block_from_ir.5b8d0698.png"},function(t,a,s){t.exports=s.p+"assets/img/lec2_example_of_build_control_flow_graph.7a6a35be.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_what_is_data_flow_analysis.8d9ea9c6.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_what_is_reaching_definition.64d502a4.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_gen_b_and_kill_b.59a36384.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_reaching_definition_control_flow_handling.250cd63e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_itertive_algorithm_of_reaching_definition.eef6472f.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_reaching_definition_start_state.8510466a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_reaching_definition_stop_state.f2c4132c.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_waht_is_living_variable_analysis.de284deb.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_transfer_function_of_live_variable_analysis.797b4a26.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_itertive_algorithm_of_live_variable.d3a609b8.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_live_variable_start_state.7e231447.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_live_variable_stop_state.be498c29.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_what_is_available_expression_analysis.e73bbbe7.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_transfer_function_of_available_expression_analysis.f79d7d7a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_itertive_algorithm_of_available_expression.29f755ea.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_available_expression_start_state.bd7da095.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_example_of_available_expression_stop_state.2a798ffb.png"},function(t,a,s){t.exports=s.p+"assets/img/lec3_summary.be322d80.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_fix_pointer_view_of_itertive_alogrithm.3d75013f.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_definition_of_upper_bound_and_lower_bound.6edc6a33.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_example_of_poset_without_glb.d35d2a8b.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_example_of_lattice_shape.a81b5aac.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_data_flow_analysis_framework_via_lattice.523219e9.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_monotonicity_and_fix_point_theorem.77e4a591.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_proof_of_fixed_point_theorem.7812a2c1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_relate_iterative_algoritm_to_fixed_point_theorem.5249f748.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_answer_to_the_three_question.9152f953.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_lattice_view_of_may_and_must_analysis.37f174d1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_meet_over_all_path_solution.b5c88180.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_compare_iterative_algorithm_and_mop.bf84776b.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_what_is_constant_propagation.903dedd1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_constant_propagation_on_lattice.c57a38a8.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_transer_function_of_constant_propagation.6152c833.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_constant_propagation_nondistributivity.eba26f55.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_review_iterative_algorithm_for_may_forward_analysis.be589656.png"},function(t,a,s){t.exports=s.p+"assets/img/lec4_worklist_algorhtm_of_forward_may_analysis.dde6d0a0.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_signature_of_method_in_java.6b2cc2bd.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_method_dispatch_of_virtual_calls.332b1f40.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_example_of_dispatch_virtual_call.c36cb42f.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_what_is_classs_hierarchy_analysis.a28eb109.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_algorithm_of_call_resolution_of_cha.ab95f140.png"},function(t,a,s){t.exports=s.p+"assets/img/lec5_example_of_cha.1ff44b38.png"},function(t,a,s){t.exports=s.p+"assets/img/lec7_example_of_build_call_graph_use_cha_start_state.b7bdc8c3.png"},function(t,a,s){t.exports=s.p+"assets/img/lec7_example_of_build_call_graph_use_cha_stop_state.03ed070b.png"},function(t,a,s){t.exports=s.p+"assets/img/lec7_example_of_iterprocedural_control_flow_graph.111914b3.png"},function(t,a,s){t.exports=s.p+"assets/img/lec7_example_of_interprocedural_constant_propagation.f259b97f.png"},function(t,a,s){t.exports=s.p+"assets/img/lec7_example_of_intraprocedural_constant_propagation.58979476.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_problem_of_cha.b0c81111.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_is_pointer_analysis.ce4fae0a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_example_of_simple_pointer_analysis.7860375e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_key_factors_in_pointer_analysis.54cf1aa8.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_conert_in_this_course_about_pointer_analysis.fde84ca0.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_is_allocation_site_abstraction.81b65ae4.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_is_context_sensitivity.00477b58.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_is_flow_sensitivity.be8d8186.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_what_is_analysis_scope.0b756a85.png"},function(t,a,s){t.exports=s.p+"assets/img/lec8_pointers_in_java.aef18e27.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_domain_and_notations_of_context_insensitive_pointer_analysis.bb67185d.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_rules_of_context_insensitive_pointer_analysis.cefe18de.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_how_to_implement_pointer_analysis.9b808952.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_definition_of_pointer_flow_graph.b321afe1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_edges_in_pointer_flow_graph.236d8df1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_example_of_pointer_flow_graph.7ba1da54.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_build_pointer_flow_graph_and_propagate_points_to_information_on_pfg.624b3c89.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_worklist_of_context_insensitive_pointer_analysis.ecb1699a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_algorithm_for_context_insensitive_pointer_analysis.71d0fe52.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_differential_propagation_of_pointer_analysis.47e31654.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_example_of_context_insensitive_pointer_analysis_start_state.b83a2349.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_example_of_context_insensitive_pointer_analysis_stop_state.e7a53950.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_pointer_analysis_in_the_presence_of_method_invocations.4f60bf8d.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_rule_of_method_call_in_pointer_analysis.fa5f76b2.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_pointer_analysis_algorithm_with_method_call.b8579906.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_example_of_pointer_analysis_with_method_call_start_state.b9bb1765.png"},function(t,a,s){t.exports=s.p+"assets/img/lec9_example_of_pointer_analysis_with_method_call_stop_state.23c5eb1e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_problem_of_context_insensitive_pointer_analysis.1e8ef8ab.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_what_is_cloning_based_context_sensitivity.90ba112e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_context_sensitive_pointer_analysis.7dfec206.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_context_sensitive_heap.cd8f2fce.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_context_insensitive_and_context_sensitive_heap.8b08e1be.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_domain_and_notations_of_context_insensitive_pointer_analysis.08039397.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_rules_of_context_sensitive_pointer_analysis.8c9b0e67.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_rules_2_of_context_sensitive_pointer_analysis.6d943f93.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_rules_of_method_call_in_context_sensitive_pointer_analysis.ef7b4395.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_rules_2_of_method_call_in_context_sensitive_pointer_analysis.cda95a14.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_how_to_implement_context_sensitive_pointer_analysis.90e76a6f.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_pointer_flow_graph_with_cs.c903ce31.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_context_sensitive_pointer_analysis_algorithm.f6360e9a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_context_insensitive_pointer_analysis_algorithm.c53559c1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_context_sensitivity_variants.96204b97.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_what_is_call_site_sensitivity.1072ce0c.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_call_site_sensitivity.8be77ccd.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_what_is_k_call_site_sensitivity.880bb7c5.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_1_call_site_start_state.58280313.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_example_of_1_call_site_stop_state.653c7dbb.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_compare_ci_with_1_call_site.9a7f520c.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_what_is_object_sensitivity.9fe1122e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_compare_1_call_site_and_object.1e381ec5.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_compare_1_call_site_and_object_2.4d692d93.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_compare_object_and_1_call_site.4d2c050a.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_what_is_type_sensitivity.9ddd87c1.png"},function(t,a,s){t.exports=s.p+"assets/img/lec11_statistical_data_of_call_site_object_and_type_sensitivity.aec2bceb.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_so_many_implementation_details_in_pointer_analysis.e666cfd5.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_implementation_of_pointer_analysis.920b9e34.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_atom_in_datalog.ec22146e.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_logic_in_datalog.895d3c05.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_example.68ed0863.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_program.62867f8c.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_edb_and_idb_in_datalog.d6085b66.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_rule_safety_in_datalog.a93ff61d.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_pointer_analysis_via_datalog.65abacf5.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_model_for_pointer_analysis.0b4060bb.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_rules_for_pointer_analysis.0b6eb356.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_rules_for_pointer_analysis_method_call.277583de.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_whole_program_pointer_analysis.2c1339ce.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_datalog_model_for_taint_analysis.153e8835.png"},function(t,a,s){t.exports=s.p+"assets/img/lec14_taint_analysis_via_datalog.56b7a79e.png"},,,,,,,,,,,,,,,function(t,a,s){"use strict";s.r(a);var e=s(2),n=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"static-program-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#static-program-analysis"}},[t._v("#")]),t._v(" Static Program Analysis")]),t._v(" "),a("h2",{attrs:{id:"write-in-front"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#write-in-front"}},[t._v("#")]),t._v(" Write in Front")]),t._v(" "),a("p",[t._v("HomePage: "),a("a",{attrs:{href:"https://tai-e.pascal-lab.net/lectures.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("Static Program Analysis"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"lec1-introduction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec1-introduction"}},[t._v("#")]),t._v(" Lec1 Introduction")]),t._v(" "),a("p",[t._v("首先需要对 Static Analysis 有一个比较宏观的印象，其属于 PL 应用下的一个分发，出现的背景是虽然编程语言最核心的部分在过去的很长一段时间里，都没有发生本质的变化，但是程序的规模和复杂性却与日俱增，那么该如何确保程序的可靠性、安全性以及其他的一些保证？")]),t._v(" "),a("p",[t._v("也许你会说做好 code review，确实，但将这项艰巨的任务交给人实在是不优雅，程序的事情就让程序自己来解决好了，这就是 Static Analysis 的背景（我以为的）。")]),t._v(" "),a("p",[t._v("深入学习静态程序分析的附加值：")]),t._v(" "),a("ul",[a("li",[t._v("更深入的理解编程语言的语法、语义")]),t._v(" "),a("li",[t._v("自然而然的写出更可靠、更安全、更高效的程序")])]),t._v(" "),a("p",[t._v("那么，究竟什么是程序分析呢？一般认为，程序分析是在程序运行前通过分析出是否具有某些性质。比如，是否存在隐私信息泄漏，是否解引用了空指针，是否安全的进行类型转换，等等等等。")]),t._v(" "),a("p",[t._v("但，有如下定理说明是不可能的。")]),t._v(" "),a("blockquote",[a("p",[t._v("Any non-trivial property of the behavior of programs in a recursively enumerable language is undecidable. - Rice's Theorem")])]),t._v(" "),a("p",[t._v("莱斯定理很像香农定理之余信息论，并非在否定该方向的发展，而是给定了一个理论上界。")]),t._v(" "),a("p",[t._v("一个好的静态分析，应该在保证尽量接近 soundness 的基础上，在分析精度和分析速度之间权衡。")]),t._v(" "),a("p",[t._v("（算了，这部分不太想写，内容太零碎了，等等再说吧。")]),t._v(" "),a("h2",{attrs:{id:"lec2-intermediate-representation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec2-intermediate-representation"}},[t._v("#")]),t._v(" Lec2 Intermediate Representation")]),t._v(" "),a("p",[t._v("源代码到机器代码需要经过词法分析、语法分析、语义分析，然后翻译成 IR，再生成机器代码，整个流程如下图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(435),alt:""}})]),t._v(" "),a("p",[t._v("从图里可以看出，Static Analysis 一般是基于 IR 的，因为前面一些 trivial 的工作，比如语法解析之类，没必要重复做，至于为什么不使用 AST，主要是 IR 的通用性更好，更底层更接近机器代码，语言无关，而且还包含清晰的控制流信息。")]),t._v(" "),a("p",[t._v("当然，IR 也有多种表示形式，比如常见的有 3AC 和 SSA，而课程用到的则是 Tai-e 的 IR。")]),t._v(" "),a("h3",{attrs:{id:"control-flow-graph"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#control-flow-graph"}},[t._v("#")]),t._v(" Control Flow Graph")]),t._v(" "),a("p",[t._v("虽然 Static Analysis 是基于 IR 的，但并不是直接在 IR 上进行分析，而是将 IR 构建成图模型，比如说这里要说的 Control Flow Graph。")]),t._v(" "),a("p",[t._v("在 CFG 里，最小的单元是 Basic Block，每一个 Basic Block 需要保证只能一个入口和一个出口，即从 Basic Block 的第一条指令进入，从 Basic Block 的最后一条指令出去。")]),t._v(" "),a("p",[t._v("那么，如何将 IR 切分成 Basic Block 呢？感觉这里有一点贪心的思想在里面，即在满足 Basic Block 条件的前提下，尽可能的使得每个 Basic Block 最大化。那么，实际上确定每个 Basic Block 的起始指令和结束指令就可以了。于是，可以得到如下的算法：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(436),alt:""}})]),t._v(" "),a("p",[t._v("对应给出一个例子：\n"),a("img",{attrs:{src:s(437),alt:""}})]),t._v(" "),a("p",[t._v("CFG 既然是图，那么出了节点（Basic Block）之外，还需要边，思考该如何加边。首先，IR 到 CFG 的转换过程中，不应该损失信息，那么添加的边必然是原先在 IR 中就存在的，比如说条件跳转和顺序关系。实际上，差不多也就只有这两种情况了。")]),t._v(" "),a("p",[t._v("Basic Block A 到 Basic Block B 之间有一条表，当前仅当如下两种情况：")]),t._v(" "),a("ol",[a("li",[t._v("A 的最后一条指令跳转（条件跳转或无条件跳转）到 B；")]),t._v(" "),a("li",[t._v("B 紧跟在 A 之后，并且 A 的最后一条语句不是无条件跳转。")])]),t._v(" "),a("p",[t._v("加上边的 CFG 如下图所示：\n"),a("img",{attrs:{src:s(438),alt:""}})]),t._v(" "),a("p",[t._v("可以看到，最终生成的 CFG 中多个两个 Basic Block，即 Entry 和 Exit，这是为了方便算法的实现。")]),t._v(" "),a("h2",{attrs:{id:"lec3-4-data-flow-analysis-application"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec3-4-data-flow-analysis-application"}},[t._v("#")]),t._v(" Lec3~4 Data Flow Analysis - Application")]),t._v(" "),a("p",[t._v("Static Analysis 的理论是比较抽象的，所以先举几个例子，近几节课主要研究 Data Flow Analysis，有如下经典的例子：")]),t._v(" "),a("ul",[a("li",[t._v("Reaching Definition Analysis")]),t._v(" "),a("li",[t._v("Live Variable Analysis")]),t._v(" "),a("li",[t._v("Available Expression Analysis")])]),t._v(" "),a("p",[t._v("在那之前，先来搞明白什么是 Data Flow Analysis。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(439),alt:""}})]),t._v(" "),a("p",[t._v("可知设计 DFA 可以从如下几个方面考虑：")]),t._v(" "),a("ul",[a("li",[t._v("data abstraction")]),t._v(" "),a("li",[t._v("flow safe-approximation")]),t._v(" "),a("li",[t._v("transfer function")]),t._v(" "),a("li",[t._v("control-flow handling")])]),t._v(" "),a("p",[t._v("在 DFA 中，会在每一个 Program Point 上附加一个一些数据，这些数据是在该 Program Point 处可以观测到的程序状态。")]),t._v(" "),a("h3",{attrs:{id:"reaching-definition-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reaching-definition-analysis"}},[t._v("#")]),t._v(" Reaching Definition Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(440),alt:""}})]),t._v(" "),a("p",[t._v("通过在 CFG 的起始节点给所有变量一个不合法的 Definition，那么如果这个 Definition 可以流到变量被使用的地方，就说明出现了 use before define 的情况。")]),t._v(" "),a("p",[t._v("从之前说的四个方面来讲解 Reaching Definition Analysis，即 data abstraction、flow safe-approximation、transfer function 和 control-flow handling。")]),t._v(" "),a("p",[t._v("先来思考数据抽象是什么，不妨从分析的目的的角度来考虑，Reaching Definition Analysis 要分析的是某个 Definition 是否可以流到某个程序点处，那么，就可以定义一个位图，来标识某程序点处是否有其 Definition。")]),t._v(" "),a("p",[t._v("然后再来考虑 flow safe-approximation，显然易知，只要有一条从 q 到 p 的路径，就应该认为 Definition Reach 了，所以这是 may analysis。")]),t._v(" "),a("p",[t._v("接着考虑 transfer function，tansfer function 应用在 CFG 中的节点上，表示数据如何进行状态转换。在 Reaching Definition Analysis 的语境下，容易想到如下的 trafer function：")]),t._v(" "),a("p",[t._v("$$\nOUT[B] = gen_{B} \\cup (IN[B] - kill_{B})\n$$")]),t._v(" "),a("p",[t._v("如何理解呢？这是一个 forward analysis，所以输出是 OUT[B] 自然不用讲。那么在每一个 Basic Block 中，状态如何转移？不妨举个例子，"),a("code",[t._v("d: v = x + 1")]),t._v("，那么这个时候变量 "),a("code",[t._v("v")]),t._v(" 对应的 Definition 在其所在的 Basic Block 是 Reaching 的，同时该 Definition 还会让他处的关于 "),a("code",[t._v("v")]),t._v(" 的 Definition 变得不 Reaching，这两部分分别对应 transfer function 里的 $gen_{B}$ 和 $kill_{B}$。同时，可以发现，$gen_{B}$ 和 $kill_{B}$ 都只是和当前 Basic Block 相关，换句话说，这些都是静态的在 DFA 进行之前就可以确定的。")]),t._v(" "),a("p",[t._v("这么说还说太抽象，举个例子。\n"),a("img",{attrs:{src:s(441),alt:""}})]),t._v(" "),a("p",[t._v("最后来考虑 control-flow handling，control-flow 在 CFG 里的表现形式是 Basic Block 之间的交汇，比如上图里的 B2 和 B3 交汇于 B4 处，那么在 B4 处如何处理来自 B2 和 B3 的数据呢？从语义上考虑，无论是从 B2 流过来还是从 B3 流过来，都是有可能达到 B4 的，这也就是前面说的 may analysis，所以在 B4 处应该对交汇来的数据取并集，即：")]),t._v(" "),a("p",[t._v("$$\nIN[B] = \\cup _{P ; a ; predecessor B} OUT[P]\n$$")]),t._v(" "),a("p",[a("img",{attrs:{src:s(442),alt:""}})]),t._v(" "),a("p",[t._v("至此就可以写出完整的迭代算法：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(443),alt:""}})]),t._v(" "),a("p",[t._v("初看起来，这很像是 CFG 上的广度优先遍历，确实；也有些像是有限状态机（FSM），确实；也有点儿像布尔可满足性问题（SAT），确实。")]),t._v(" "),a("p",[t._v("但无论说它像什么，都有以下三个问题尚未解决：")]),t._v(" "),a("ol",[a("li",[t._v("该算法一定会停止么？")]),t._v(" "),a("li",[t._v("算法的停止状态一定只有一个么？如果多余一个，如何证明算法得到的那一个状态一定是最优的？")]),t._v(" "),a("li",[t._v("若算法会停止，该如何找到这个状态呢？")])]),t._v(" "),a("p",[t._v("这些稍后再说，先给出一个例子(建议手推一下)：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(444),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(445),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"live-variable-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#live-variable-analysis"}},[t._v("#")]),t._v(" Live Variable Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(446),alt:""}})]),t._v(" "),a("p",[t._v("活跃变量分析给我的感觉很像是在分析 Variable 的 Non-Lexical Lifetime。这里稍微提一下，一般说 Lifetime，都是 Lexical Lifetime，即从声明开始一直到整个语句块结束，此时生命周期是严格按照词法中的作用域范围绑定的。这种设计看起来很简单，但在某些情况下会过于保守甚至严苛，以至于不实用，比如说在 Rust 里，考虑一个非常常见的使用数组切片的例子：")]),t._v(" "),a("div",{staticClass:"language-rust line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-rust"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("capitalize")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" c "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" data "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("make_ascii_uppercase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("foo")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Vec")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("char")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("vec!")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'b'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'c'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'e'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("capitalize")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("..")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'d'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'f'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    data\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" v "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("foo")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("println!")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"{:#?}"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br")])]),a("p",[t._v("调用"),a("code",[t._v("capitalize()")]),t._v(" 时传参会创建一个临时的 "),a("code",[t._v("&mut")]),t._v(" 型引用，并在函数结束后销毁，因而返回 "),a("code",[t._v("foo")]),t._v(" 函数里仍旧可以继续使用 "),a("code",[t._v("data")]),t._v(" 对数据进行操作。")]),t._v(" "),a("p",[t._v("但如果我手动的把传参创建的临时变量写出来呢？")]),t._v(" "),a("div",{staticClass:"language-diff line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-diff"}},[a("code",[t._v("diff --git a/src/main.rs b/src/main.rs\nindex ab972d0..5be7813 100644\n"),a("span",{pre:!0,attrs:{class:"token coord"}},[t._v("--- a/src/main.rs")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token coord"}},[t._v("+++ b/src/main.rs")]),t._v("\n@@ -351,7 +351,8 @@ fn capitalize(data: &mut [char]) {\n\n"),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[t._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("fn foo() -> Vec<char> {\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[t._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    let mut data = vec!['a', 'b', 'c', 'e'];\n")])]),a("span",{pre:!0,attrs:{class:"token deleted-sign deleted"}},[a("span",{pre:!0,attrs:{class:"token prefix deleted"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    capitalize(&mut data[..]);\n")])]),a("span",{pre:!0,attrs:{class:"token inserted-sign inserted"}},[a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    let slice = &mut data[..];\n")]),a("span",{pre:!0,attrs:{class:"token prefix inserted"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    capitalize(slice);\n")])]),a("span",{pre:!0,attrs:{class:"token unchanged"}},[a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[t._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    data.push('d');\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[t._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    data.push('f');\n")]),a("span",{pre:!0,attrs:{class:"token prefix unchanged"}},[t._v(" ")]),a("span",{pre:!0,attrs:{class:"token line"}},[t._v("    data\n")])])])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br")])]),a("p",[t._v("那很抱歉，如果按照 Lexical Lifetime 来分析的话，可变引用 "),a("code",[t._v("slice")]),t._v(" 的生命周期直到 "),a("code",[t._v("foo()")]),t._v(" 函数最后才结束，那么就同时存在多个可变引用了，因而无法通过编译。")]),t._v(" "),a("p",[t._v("这看起来没问题，但用起来是真难受，明明只是把 "),a("code",[t._v("slice")]),t._v(" 当作临时变量，并且显式写出来了，编译器为啥不能聪明一点？")]),t._v(" "),a("p",[t._v("这个例子也许会说算了算了，不把 "),a("code",[t._v("slice")]),t._v(" 写出来不就好了，那，再看下面这个例子：")]),t._v(" "),a("div",{staticClass:"language-rust line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-rust"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("proces_or_default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_mut")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Some")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("process")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("None")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("insert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("default")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br")])]),a("p",[t._v("定义一个函数，如果 HashMap 里存在相应的 entry 就进行操作，否则插入默认值。看起来很好，但很遗憾的是，无法通过编译（注，HashMap 的 API 在 Rust 2018 有了一些改动，但这不是这里要讨论的问题所在）。因为编译器认为调用 "),a("code",[t._v("map.get_mut(&key)")]),t._v(" 的时候，产生了一个临时的执行 map 的 "),a("code",[t._v("&mut")]),t._v(" 引用，并且返回值也包含了一个引用，且返回的引用的生命周期不比参数的生命周期短，而参数的生命周期显然是整个函数体，那么第 5 行通过数据的持有者 map 来修改数据会不通过，即同时存在了两个可变引用。")]),t._v(" "),a("p",[t._v("为了绕过 Lexical Lifetime Check，需要写成类似如下的形式：")]),t._v(" "),a("div",{staticClass:"language-rust line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-rust"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("proces_or_default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("contains")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("match")]),t._v(" map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_mut")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Some")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("None")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token macro property"}},[t._v("unreachable!")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("insert")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("default")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get_mut")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("unwrap")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br")])]),a("p",[t._v("实际上是通过 "),a("code",[t._v("if")]),t._v(" 缩小了生命周期，当然，目前版本的 HashMap 已经好用很多的了，可以很方便的写出：")]),t._v(" "),a("div",{staticClass:"language-rust line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-rust"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("fn")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-definition function"}},[t._v("proces_or_default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Default")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HashMap")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("K")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("->")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),a("span",{pre:!0,attrs:{class:"token lifetime-annotation symbol"}},[t._v("'m")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("mut")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("entry")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("or_insert_with")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token closure-params"}},[a("span",{pre:!0,attrs:{class:"token closure-punctuation punctuation"}},[t._v("|")]),a("span",{pre:!0,attrs:{class:"token closure-punctuation punctuation"}},[t._v("|")])]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("V")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("::")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("default")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("这反映出至少就 Rust 而言，基于 AST 做生命周期分析是一件吃力不讨好的事情，因而 Rust 的生命周期目前是基于 IR 的 Non-Lexical Lifetime。")]),t._v(" "),a("p",[t._v("扯远了，继续说回 Live Variable Analysis。同样从上面提到的四个方面来分析如何设计算法。这里不再详述，直接给出。需要注意的是，这次是 forward may analysis。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(447),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(448),alt:""}})]),t._v(" "),a("p",[t._v("同样的给出一个例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(449),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(450),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"available-expression-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#available-expression-analysis"}},[t._v("#")]),t._v(" Available Expression Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(451),alt:""}})]),t._v(" "),a("p",[t._v("这个我感觉是在分析是否能重用上一次表达式的计算结果，那么就需要表达式中的变量在两次计算之间没有被重新定义或者赋值。")]),t._v(" "),a("p",[t._v("这一次和之前的略有不同，是一个 forward must analysis，因为重用计算结果需要确保在所有可能的路径上都是成立的才能进行优化，这使得在初始化的时候，会有些不同。")]),t._v(" "),a("p",[t._v("同样的，直接给出算法。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(452),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(453),alt:""}})]),t._v(" "),a("p",[t._v("同样的，给出例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(454),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(455),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#summary"}},[t._v("#")]),t._v(" Summary")]),t._v(" "),a("p",[a("img",{attrs:{src:s(456),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec5-6-data-flow-analysis-foundations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec5-6-data-flow-analysis-foundations"}},[t._v("#")]),t._v(" Lec5~6 Data Flow Analysis Foundations")]),t._v(" "),a("h3",{attrs:{id:"fix-pointer-view-of-dfa"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fix-pointer-view-of-dfa"}},[t._v("#")]),t._v(" Fix Pointer View of DFA")]),t._v(" "),a("p",[t._v("换一个视角来思考上一讲的迭代算法：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(457),alt:""}})]),t._v(" "),a("p",[t._v("会发现迭代算法就是在给定状态下求不动点。")]),t._v(" "),a("p",[t._v("那么在前面 Reaching Definition Analysis 哪里遗留的三个问题就可以换一种更明确的表述了：")]),t._v(" "),a("ol",[a("li",[t._v("迭代算法是否可以达到不动点以终止，或者说问题是否总是有解？")]),t._v(" "),a("li",[t._v("如果存在不动点，那么是否只有一个？如果有多个，如何保证算法得到的一定是精度最好的那一个？")]),t._v(" "),a("li",[t._v("迭代算法何时才能到达不动点？")])]),t._v(" "),a("p",[t._v("此时可以解决这三个问题了，虽然又到了"),a("s",[t._v("枯燥")]),t._v("有趣的数学时间了。")]),t._v(" "),a("h3",{attrs:{id:"partial-order"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#partial-order"}},[t._v("#")]),t._v(" Partial Order")]),t._v(" "),a("p",[t._v("定义偏序集（poset）为一个二元组 $(P,  \\sqsubseteq )$，其中 $ \\sqsubseteq $ 定义了一个 $P$ 上的偏序关系，当然其本身是一个二元关系，并且 $ \\sqsubseteq $ 有如下性质：")]),t._v(" "),a("ol",[a("li",[t._v("自反性（$\\forall x \\in P,x \\sqsubseteq x$）")]),t._v(" "),a("li",[t._v("反对称性（$\\forall x,y \\in P,x \\sqsubseteq y \\wedge y \\sqsubseteq x \\Rightarrow x = y$）")]),t._v(" "),a("li",[t._v("传递性（$\\forall x,y,z \\in P,x \\sqsubseteq y \\wedge y \\sqsubseteq z \\Rightarrow x \\sqsubseteq z$）")])]),t._v(" "),a("p",[t._v("传递性其实是比较容易满足的，主要还是自反性和反对称性。比如说整数集上的 $\\le$ 定一个了一个偏序关系，但 $\\lt$ 并不是，因为不满足自反性。")]),t._v(" "),a("p",[t._v("既然是一个排序关系，那么自然会想到是否存在最大最小值之类的问题，给出如下定义：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(458),alt:""}})]),t._v(" "),a("p",[t._v("即上界（UB）、下界（LB）、上确界（LUB）、下确界（GLB）。")]),t._v(" "),a("p",[t._v("当然，并非所有的 poset 都有这四个边界，比如下面的例子就没有 glb。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(459),alt:""}})]),t._v(" "),a("p",[t._v("又合理的想到，偏序关系里是否存在一些特殊的值得研究的情况呢？还真有，就是下面要说的 Lattice。")]),t._v(" "),a("h3",{attrs:{id:"lattice"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lattice"}},[t._v("#")]),t._v(" Lattice")]),t._v(" "),a("p",[t._v("在 poset 里找出一些比较特殊的，即对 poset 里的任意两个元素来说，LUB 和 GLB 都成立的话，就称 $(P, \\sqsubseteq)$ 构成一个 Lattice。")]),t._v(" "),a("p",[t._v("Lattice 的例子比如定义在整数集合上的 $\\le$，前面说了构成偏序关系，又任意两个元素 $a,b$ 的 LUB 可以认为是 "),a("code",[t._v("Max(a, b)")]),t._v("，而 GLB 可以认为是 "),a("code",[t._v("Min(a, b)")]),t._v("。")]),t._v(" "),a("p",[t._v("可以想像的到，如果把 Lattice 画出来，应该都是类似下面的形状，即从某一个特定的 source 一直按照某一个特定的方向流入到某一个特定的 destination。其中，特定的方向实际上就是偏序关系 $\\sqsubseteq$，特定的 source 是保证 LUB 的存在，记作 top（T），特定的 destination 则是保证 GLB 的存在，记作 bottom（$\\perp$）。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(460),alt:""}})]),t._v(" "),a("p",[t._v("说错哩，前面一直在说 complete lattice，这是 lattice 里最特殊的情况，像上面的图里面，已经不是 lattice 定义里的分析元素之间的关系了，变成了分析子集之间的关系。但不算太重要，知道 complete lattice 够用了。")]),t._v(" "),a("p",[t._v("另外，将 Product Lattice 定义为两个 Latiice 之间的笛卡尔积，易知，complete lattice 的 product 仍然是 complete lattice。")]),t._v(" "),a("p",[t._v("至此，可以用 Lattice 来建模 DFA，将 DFA 定义为三元组 $(D, L, F)$。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(461),alt:""}})]),t._v(" "),a("p",[t._v("那么，就可以将 DFA 看作是在 lattice 上迭代的应用 trafer function 和 control-flow handling。")]),t._v(" "),a("h3",{attrs:{id:"fix-point-theorem"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fix-point-theorem"}},[t._v("#")]),t._v(" Fix Point Theorem")]),t._v(" "),a("p",[t._v("前面只是将问题换了一个论域，但并未解决任何一个问题，有一种浅显的感觉，答案和单调性有关，确实是：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(462),alt:""}})]),t._v(" "),a("p",[a("s",[t._v("这里的单调性怎么这么像协变的定义啊")])]),t._v(" "),a("p",[t._v("不动点原理可以用鸽笼来简单的证明：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(463),alt:""}})]),t._v(" "),a("p",[t._v("至此，可以将 DFA 和不动点原理关联起来。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(464),alt:""}})]),t._v(" "),a("p",[t._v("那么，现在还需要解决的事情就是证明 trafer function 以及 control-flow handling 的单调性。")]),t._v(" "),a("p",[t._v("transfer function 的单调性是好说明的，比如 Reaching Definition Analysis 里的 transfer function：")]),t._v(" "),a("p",[t._v("$$\nOUT[B] = gen_{B} \\cup (IN[B] - kill_{B})\n$$")]),t._v(" "),a("p",[t._v("$gen_{B}$ 和 $kill_{B}$ 都是固定的，而且是取并集，那么只存在 $0 \\to 1$ 的转变，即满足反对称性。")]),t._v(" "),a("p",[t._v("至此，前两个问题通过不动点理论可以得解，即算法存在不动点，虽然不动点的数量可能不止一个，但可以保证求得的是最优的（即最大不动点或最小不动点）。")]),t._v(" "),a("p",[t._v("那么，算法何时停止呢？或者说算法的时间复杂度是怎样的。")]),t._v(" "),a("p",[t._v("因为每一次都是在 lattice 的一次状态转移，那么对于高度为 $H$ 的 lattice 来说，每一个 program point 最多进行 $H$ 次状态转移，若记 program point 的数量为 $k$，则算法最坏情况下的时间复杂度为 $k * H$。")]),t._v(" "),a("p",[t._v("至此，三个问题得解。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(465),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"lattice-view-of-may-and-must-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lattice-view-of-may-and-must-analysis"}},[t._v("#")]),t._v(" Lattice View of May and Must Analysis")]),t._v(" "),a("p",[t._v("还有一个前面没有说清楚的问题，即 May Analysis 和 Must Analysis 的区别。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(466),alt:""}})]),t._v(" "),a("p",[t._v("上面对比图很直观的说明了问题，不管是 May Analysis 还是 Must Analysis，都是从 unsafe state 往 Safe but Useless state 转移，中途在不动点出停下来。那么，根据语义找到 Safe but Useless state，另一边就是迭代的起始状态了。")]),t._v(" "),a("p",[t._v("拿 Live Variable Analysis 来说，这是一个 may backward analysis，在某一点处 Safe but Useless state 是什么呢？显然是所有变量都可能存活，即 top，其对应的状态是所有变量都不可能存活，即 bottom，而 may analysis 是从 bottom 到 top 的转移，所以就可以确定初始状态了。")]),t._v(" "),a("h3",{attrs:{id:"meet-over-all-path-mop"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#meet-over-all-path-mop"}},[t._v("#")]),t._v(" Meet Over All Path(MOP)")]),t._v(" "),a("p",[t._v("前面说迭代算法像图的广度优先遍历，那么自然会好奇是否存在深度优先遍历。是有的，即这里说的 MOP。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(467),alt:""}})]),t._v(" "),a("p",[t._v("那么，两种方法最终的结果相同么？如果不相同，谁的精度好一些？")]),t._v(" "),a("p",[a("img",{attrs:{src:s(468),alt:""}})]),t._v(" "),a("p",[t._v("上图是按照 may analysis 得到的 Ours is less precise than MOP 的结论，因为 $MOP \\sqsubseteq Ours$ 表明 MOP 在 lattic 上更接近 bottom，也即精度更好。")]),t._v(" "),a("p",[t._v("但是当 transfer function 是可分配的时候，两者在精度上是没有区别的。")]),t._v(" "),a("p",[t._v("而前面的几个例子都是集合的交并操作，这些都是满足分配律的，因而前面的例子两种方式的精度是相同的。")]),t._v(" "),a("h3",{attrs:{id:"constant-propagation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#constant-propagation"}},[t._v("#")]),t._v(" Constant Propagation")]),t._v(" "),a("p",[t._v("前面的例子中，transfer function 都是满足分配律的，下面介绍不满足分配律的例子，即 Constant Propagation。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(469),alt:""}})]),t._v(" "),a("p",[t._v("Constant Propagation 研究的是在 Program Point P 这一点变量 x 的值是否是一个恒定的常量。")]),t._v(" "),a("p",[t._v("然后来定义 lattice，Domain 的话，就是 UNDEF、C、NAC 三种情况。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(470),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(471),alt:""}})]),t._v(" "),a("p",[t._v("随便找个例子，用反正法证明 Constant Propagation 的 transfer function 不满足分配律：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(472),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"worklist-alogirithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#worklist-alogirithm"}},[t._v("#")]),t._v(" WorkList Alogirithm")]),t._v(" "),a("p",[t._v("在前面手推状态转移的时候，会发现其实很多情况是不需要重复计算的，比如输入不变的情况下，输出一般都是不变的，因而就有了对迭代算法的优化，引入 WorkList 的概念。")]),t._v(" "),a("p",[t._v("比较好理解，就直接那前面 Available Expression 的例子来说明吧。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(473),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(474),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec7-interprocedural-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec7-interprocedural-analysis"}},[t._v("#")]),t._v(" Lec7 Interprocedural Analysis")]),t._v(" "),a("p",[t._v("前面的几个例子，都只是分析了代码片段，或者说都没有跨函数分析，像在 Constant Propagation Analysis 的时候，为了保守期间，只要是函数调用，都认为是 NAC，这会对精度造成很大的损失。因而有了 Interprocedural Analysis 来进行函数间调用分析。")]),t._v(" "),a("p",[t._v("Interprocedural Analysis 是需要 Call Graph 的，对于 OOPL 来说，构建 Call Graph 有四种方法：")]),t._v(" "),a("ol",[a("li",[t._v("Class hierarchy analysis(CHA)")]),t._v(" "),a("li",[t._v("Rapid type analysis(RTA)")]),t._v(" "),a("li",[t._v("Variable type analysis(VTA)")]),t._v(" "),a("li",[t._v("Pointer analysis(k-CFA)")])]),t._v(" "),a("p",[t._v("速度方面：CHA > RTA > VTA > k-CFA\n精度方面：k-CFA > VTA > RTA > CHA")]),t._v(" "),a("h3",{attrs:{id:"function-call-in-java"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#function-call-in-java"}},[t._v("#")]),t._v(" Function Call In Java")]),t._v(" "),a("p",[t._v("因为主要是针对 Java 进行静态分析，那么首先需要先了解 Java 里存在的几种函数调用：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("Static Call")]),t._v(" "),a("p",[t._v("invokestatic，主要是调用静态方法的，所以在编译期就可以决议出目标方法。")])]),t._v(" "),a("li",[a("p",[t._v("Special Call")]),t._v(" "),a("p",[t._v("invokespacial，主要是调用构造方法、私有实例方法、父类实例方法，同样的也可以在编译期决议出目标方法。")])]),t._v(" "),a("li",[a("p",[t._v("Virtual Call")]),t._v(" "),a("p",[t._v("invokevirtual/invokeinterface，其余的实例方法都属于此列，这也是所谓的多态，因而需要在运行期决议目标方法。")])])]),t._v(" "),a("h3",{attrs:{id:"method-dispatch-for-virtual-call"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#method-dispatch-for-virtual-call"}},[t._v("#")]),t._v(" Method Dispatch for Virtual Call")]),t._v(" "),a("p",[t._v("主要分析的是编译期无法决议出的 Virtual Call，首先 Dispatch 需要哪些信息。首先，需要函数签名，其次，如果是 instance method，还需要有调用对象，也就是 receiver object。Java 里的函数签名有如下记法：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(475),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(476),alt:""}})]),t._v(" "),a("p",[t._v("也就是说，最先在自己的方法列表中查找，查找不到就到父类中找。举个例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(477),alt:""}})]),t._v(" "),a("p",[t._v("那么，现在的问题就变成了构建 Call Graph。")]),t._v(" "),a("h3",{attrs:{id:"class-hierarchy-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#class-hierarchy-analysis"}},[t._v("#")]),t._v(" Class Hierarchy Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(478),alt:""}})]),t._v(" "),a("p",[t._v("CHA 是基于类继承信息的，会使用 receiver variable 的 declared type 做决议，也就是说使用其静态类型。决议的实现很简单，对于 static call 直接返回方法签名；对于 special call，会拿出 signature 中的 class type 去 Dispatch；对于 virtual call，则会对于调用点处的变量的声明类型已经该声明类型的所有子类型中去 Dispatch。算法的伪代码如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(479),alt:""}})]),t._v(" "),a("p",[t._v("对于 static call 和 special call 没什么好说的，无论在哪个算法里都差不多。重点在 virtual call 的处理中，从代码中可以知道，直接把类型信息擦除了，会决议出所有可能被调用到的方法（自身类型以及所以该类型的子类型）。")]),t._v(" "),a("p",[t._v("举个例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(480),alt:""}})]),t._v(" "),a("p",[t._v("// TODO")]),t._v(" "),a("p",[t._v("这太奇怪了，为啥 "),a("code",[t._v("Resolve(a.foo())")]),t._v(" 会是这么多啊，不应该只去 "),a("code",[t._v("A")]),t._v("、"),a("code",[t._v("B")]),t._v(" 这两个类里取 Dispatch 么？不会这里的 subclass 包括子类的子类吧？")]),t._v(" "),a("p",[t._v("CHA 速度快，但不精准，一般也就 IDE 里可能会用用。在用 CHA 构建 Call Graph 的时候，一般会将 "),a("code",[t._v("main")]),t._v(" 之类的入口方法作为起始。")]),t._v(" "),a("p",[t._v("看一个例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(481),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(482),alt:""}})]),t._v(" "),a("p",[t._v("容易想到，CHA 跑完之后的不可达代码实际上也是 dead code。")]),t._v(" "),a("h3",{attrs:{id:"interprocedural-control-flow-graph"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#interprocedural-control-flow-graph"}},[t._v("#")]),t._v(" Interprocedural Control Flow Graph")]),t._v(" "),a("p",[t._v("有了 Call Graph 之后，就可以将 CFG 升级到 ICFG 了，需要在 CFG 的基础上添加 call edge 和 return edge。需要注意的是，call-to-return edge 不需要删除，因为 call edge 一般只用来传递函数的参数，而 caller 中还有其他的数据，如果删掉了 call-to-return edge 的话，这部分数据也需要经由 call edge 流向 callee，最终经由 return edge 流回 caller，这实际上不必要的开销。只要在 caller 处将流向 callee 参数的那部分数据 kill 掉即可，不会出现多条路径导致数据重复或者冲突的情况出现的。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(483),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"interprocedural-constant-propagation"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#interprocedural-constant-propagation"}},[t._v("#")]),t._v(" Interprocedural Constant Propagation")]),t._v(" "),a("p",[a("img",{attrs:{src:s(484),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(485),alt:""}})]),t._v(" "),a("p",[t._v("可以看到 Interprocedural Analysis 因为没有擦除函数调用信息，因而精度更高。")]),t._v(" "),a("h2",{attrs:{id:"lec8-pointer-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec8-pointer-analysis"}},[t._v("#")]),t._v(" Lec8 Pointer Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(486),alt:""}})]),t._v(" "),a("p",[t._v("前面提到了 CHA 来构建 Call Graph，精度并不好，哪怕是 IDE 这种场景，如果尝试跳到某个 instance method 里，出现一串可能的 target method，体验并不好，比如上面 "),a("code",[t._v("n.get()")]),t._v(" CHA 会给出 "),a("code",[t._v("Zero::get()")]),t._v("、"),a("code",[t._v("One::get()")]),t._v("、"),a("code",[t._v("Two::get()")]),t._v(" 三个结果。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(487),alt:""}})]),t._v(" "),a("p",[t._v("指针分析分析的是某一个内存位置可以被哪些指针（这里的指针并非是 C++ 里狭义上指针的概念，对 Java 而言，指针可以是 variable、instance field、array 等等）指向。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(488),alt:""}})]),t._v(" "),a("p",[t._v("虽然看起来有点儿像 Alias Analysis，但其实是不一样的，Pointer Analysis 侧重于分析指针可以指向哪些对象，而 Alias Analysis 侧重于分析是否有两个指针指向了相同的对象。")]),t._v(" "),a("p",[t._v("Pointer Analysis 的应用：")]),t._v(" "),a("ol",[a("li",[t._v("生成基础的信息，比如 Call Graph 和 Aliases 等；")]),t._v(" "),a("li",[t._v("编译优化，比如虚函数调用内联等；")]),t._v(" "),a("li",[t._v("安全分析，比如 Information Flow analysis")]),t._v(" "),a("li",[t._v("等等等等")])]),t._v(" "),a("h3",{attrs:{id:"key-factor-in-pointer-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-factor-in-pointer-analysis"}},[t._v("#")]),t._v(" Key Factor in Pointer Analysis")]),t._v(" "),a("p",[t._v("感觉上下文分析都做 heap abstraction 了，真的还算是 static analysis 么？已经算是在 Pointer Analysis 的环境里运行了吧？")]),t._v(" "),a("p",[a("img",{attrs:{src:s(489),alt:""}})]),t._v(" "),a("p",[t._v("课程里主要设计的是红色标出的这些：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(490),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"heap-abstraction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#heap-abstraction"}},[t._v("#")]),t._v(" Heap Abstraction")]),t._v(" "),a("p",[t._v("Heap Abstraction 需要对程序运行时的堆进行建模，一个首要的问题是遇到下面类似的情况，仍旧可以正常分析：")]),t._v(" "),a("div",{staticClass:"language-java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("A")]),t._v(" a "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("A")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("也就是说程序动态运行时候创建的对象数量在静态分析的时候是无法感知的，那么如何确保抽象对象的有穷性。")]),t._v(" "),a("h4",{attrs:{id:"allocation-site-abstraction"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#allocation-site-abstraction"}},[t._v("#")]),t._v(" Allocation-Site Abstraction")]),t._v(" "),a("p",[t._v("一个容易想到的方案是进程是程序的一次执行，虽然无法感知进程的信息，但是程序是静态的，那么对于每一个 Allocation-Site 都创建一个 abstract object，就可以保证其有穷性了。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(491),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"context-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context-sensitivity"}},[t._v("#")]),t._v(" Context Sensitivity")]),t._v(" "),a("p",[t._v("简单来说就是否忽略函数调用时候的上下文信息。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(492),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"flow-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flow-sensitivity"}},[t._v("#")]),t._v(" Flow Sensitivity")]),t._v(" "),a("p",[t._v("简单来说就是是否关注指令的有序性，或者说指令的顺序是否在分析的范围内。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(493),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"analysis-scope"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#analysis-scope"}},[t._v("#")]),t._v(" Analysis Scope")]),t._v(" "),a("p",[t._v("Analysis Scope 是说分析的范围是哪些，是直接全程序分析，还是需求驱动的仅仅对需要的部分进行分析。一般来说，都会进行全程序分析，虽然一次全程序分析的速度是要慢于需求驱动分析的，但是全程序分析的结果是可以重复使用的。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(494),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"concerned-statement"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#concerned-statement"}},[t._v("#")]),t._v(" Concerned Statement")]),t._v(" "),a("p",[t._v("在进行 Pointer Analysis 的时候，并非所有的指令都要去分析，比如 "),a("code",[t._v("if/else")]),t._v("、"),a("code",[t._v("switch case")]),t._v(" 这些控制流语句，并不会影响指针， 需要关注是的只有那些能影响到指针的语句。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(495),alt:""}})]),t._v(" "),a("p",[t._v("首先需要明确 Java 里的 Pointer 有哪些。主要是上图里的四种。其中 Static Field 在处理的时候和 Local Variable 基本相同，而 Array element 因为无法静态感知其数组元素个数，因而会将其看作只有一个只有一个 field 的对象，那么此时的情况和 instance field 是相同的。")]),t._v(" "),a("p",[t._v("因而，最终需要关注的 Pinter 只有如下两类：")]),t._v(" "),a("ol",[a("li",[t._v("Local Variable: x")]),t._v(" "),a("li",[t._v("Instance Field: x.f")])]),t._v(" "),a("p",[t._v("说完了 Pointer 的概念，还得说一说有哪些语句可能会影响到指针，在排除控制流语句之后，大概剩下如下五种语句：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(405),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec9-10-pointer-analysis-foundations"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec9-10-pointer-analysis-foundations"}},[t._v("#")]),t._v(" Lec9~10 Pointer Analysis Foundations")]),t._v(" "),a("p",[t._v("再看一眼上一讲说过的会影响到指针的语句:")]),t._v(" "),a("p",[a("img",{attrs:{src:s(405),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(496),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(497),alt:""}})]),t._v(" "),a("p",[a("s",[t._v("看到推导式形式化方法死去的记忆开始痛击我。")])]),t._v(" "),a("h3",{attrs:{id:"implement-pointer-analysis"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#implement-pointer-analysis"}},[t._v("#")]),t._v(" Implement Pointer Analysis")]),t._v(" "),a("p",[a("img",{attrs:{src:s(498),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"pointer-flow-graph"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pointer-flow-graph"}},[t._v("#")]),t._v(" Pointer Flow Graph")]),t._v(" "),a("p",[t._v("Pointer Analysis 是基于 PFG 的，PFG 上的节点是 Pinter，而节点之间的边表示指针的流向关系。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(499),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(500),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(501),alt:""}})]),t._v(" "),a("p",[t._v("一个问题是，在上面的图中，如果没有后面两条语句，那么变量 "),a("code",[t._v("c")]),t._v(" 和其 field f 如何建立关联呢？想不明白。")]),t._v(" "),a("p",[t._v("Pointer Analysis 里的 PFG 是动态建立的，不像之前 Data Flow Analysis 里的 CFG 是在初始的时候就由 IR 完整构建出来的。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(502),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"pointer-analysis-algorithm-without-method-call"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pointer-analysis-algorithm-without-method-call"}},[t._v("#")]),t._v(" Pointer Analysis Algorithm Without Method Call")]),t._v(" "),a("p",[a("img",{attrs:{src:s(503),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(504),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(505),alt:""}})]),t._v(" "),a("p",[t._v("这里注意一下，在 propagate point to information 的时候，是进行的增量传播，而非全量传播。首先明确 "),a("code",[t._v("pt(n)")]),t._v(" 是单调的，只会往里增加，而不会减少。其次，在 "),a("code",[t._v("AddEdge(s, t)")]),t._v(" 的时候，是进行的全量传播，会将 "),a("code",[t._v("<t, pt(s)>")]),t._v(" 加入到 WorkList 里面，可以认为将 "),a("code",[t._v("pt(s)")]),t._v(" 传递到了非联通分量里面。最后，从 WorkList 里取出数据的时候，用 Propagate 增量传播的时候，如果是刚刚新加的边，那么增量其实就是全量，而对于已联通的节点，其传递的则是增量信息（当然，由于流不敏感，且没有规定以何种顺序从 WorkList 里取 entry，有可能这时候节点还没联通，仍旧传播全量信息）。但不管怎么说，增量传播性能总是要好于全量传播的。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(506),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(507),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"pointer-analysis-algorithm-with-method-call"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pointer-analysis-algorithm-with-method-call"}},[t._v("#")]),t._v(" Pointer Analysis Algorithm With Method Call")]),t._v(" "),a("p",[t._v("前面说了影响指针的语句有如下五种：")]),t._v(" "),a("ol",[a("li",[t._v("New")]),t._v(" "),a("li",[t._v("Aasign")]),t._v(" "),a("li",[t._v("Load")]),t._v(" "),a("li",[t._v("Store")]),t._v(" "),a("li",[t._v("Method Call")])]),t._v(" "),a("p",[t._v("前面介绍了没有 Method Call 情况下的上下文不敏感的指针分析，现在加入对 Method Call 的处理。")]),t._v(" "),a("p",[t._v("通过前面对于 Pointer Analysis Alogirithm 的了解，应该有这么一种感觉，Method Call 无非也是在 PFG 上多了些连接节点的规则。")]),t._v(" "),a("p",[t._v("那么，来看看 Method Call Rule 吧，当然，Method Call 必然设计 Interprocedural Analysis，所以是需要 Call Graph 的，而 Call Graph 的构建，之前说了不太精准的 CHA，下面会介绍基于 Pointer Analysis 构建 Call Graph，会看到构建 Call Graph 和构建 Pointer to information 是同时进行的。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(508),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(509),alt:""}})]),t._v(" "),a("p",[t._v("可以看到 Method Call Rule 主要做了四件事：")]),t._v(" "),a("ol",[a("li",[t._v("Dispatch")]),t._v(" "),a("li",[t._v("传 receiver object")]),t._v(" "),a("li",[t._v("传参数")]),t._v(" "),a("li",[t._v("传返回值")])]),t._v(" "),a("p",[t._v("至于为什么不在 PFG 里加入 $x \\to m_{this}$ 这条边，我是这么这么理解的，如果加了边，那么可以理解为又是一次 Context InSensitive，并且会将此处的精度损失在整个 PFG 上传播，而每次传过去，就很像是在 Call-Site Sensitive。")]),t._v(" "),a("p",[t._v("有了 Method Call 之后的 Pointer Analysis 算法如下：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(510),alt:""}})]),t._v(" "),a("p",[t._v("之前因为没有 Method Call，实际上是 Intraprocedural Analysis，所以在算法的输入是某个 Method 的语句的集合，那么初始化的时候，将这个 Method 的 New 和 Assign 拿出来初始化就好。但加入 Method Call 之后，算法的输入就是某个函数了，而后面会跳到其他函数来分析，因而需要将对 New 和 Assign 的处理抽出来，单独封装成一个函数，也就是图里的 "),a("code",[t._v("AddReachable(m)")]),t._v("。")]),t._v(" "),a("p",[t._v("对于 Method Call 的处理，就是 ProcessCall 了，会找出语句集合里每一次和 x 相关的 Method Call，去做 Dispatch，并将 $m_{this}$ 加入到 WorkList 里。同时，如果从 Call Graph 里没有这条边（$l \\to m$），会添加进去，相应的，将 m 标记为可达方法，并处理其中的 New 和 Assign。")]),t._v(" "),a("p",[t._v("算法的主体部分倒是没有什么太大的差别。")]),t._v(" "),a("p",[t._v("看一个例子吧。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(511),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(512),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec11-12-pointer-analysis-context-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec11-12-pointer-analysis-context-sensitivity"}},[t._v("#")]),t._v(" Lec11~12 Pointer Analysis Context Sensitivity")]),t._v(" "),a("p",[a("img",{attrs:{src:s(513),alt:""}})]),t._v(" "),a("p",[t._v("Context InSensitivity Pointer Analysis 处理 Method Call 的时候，不会维护函数间调用的上下文，比如上图里的 "),a("code",[t._v("x = id(n1);")]),t._v(" 和 "),a("code",[t._v("y = id(n2)")]),t._v("，是无法区分多次对于同一个函数的调用的，哪怕是不同的 object 和不同的 parameter。")]),t._v(" "),a("p",[t._v("可以发现，问题出在多次调用了同一个方法，使得原本分离的数据流合并到了一起。一个合理的设想是，能不能在每次 Method Call 的时候，将 Method 拷贝一份，这样就可以做到限制每个 Method Call 只发生一次了，这就是我对 Context Sensitivity 的理解。这有点儿像是对 Call Stack 的抽象。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(514),alt:""}})]),t._v(" "),a("p",[a("s",[t._v("这么看起来，Rust 的生命周期标准和这里的 Context 确实是不一样的。")])]),t._v(" "),a("p",[a("img",{attrs:{src:s(515),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"context-sensitive-heap"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context-sensitive-heap"}},[t._v("#")]),t._v(" Context Sensitive Heap")]),t._v(" "),a("p",[t._v("容易想到，Method Call 的时候采用 Cloning-Based Context Sensitivity 的时候，会一起连带着将 Method 里的 Heap 一起复制一份，这样才能将数据流完全分离开来，这即使 Context Sensitive Heap。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(516),alt:""}})]),t._v(" "),a("p",[t._v("学到这里，应该可以有种直觉，C.I. + C.S. Heap 并不能提高精度，事实确实如此。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(517),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"context-sensitive-pointer-analysis-rule"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context-sensitive-pointer-analysis-rule"}},[t._v("#")]),t._v(" Context Sensitive Pointer Analysis Rule")]),t._v(" "),a("p",[a("img",{attrs:{src:s(518),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(519),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(520),alt:""}})]),t._v(" "),a("p",[t._v("基础的四条 C.S. Rule 和 C.I. Rule 的差别仅仅在于是否有上下文信息。")]),t._v(" "),a("p",[t._v("真正有区别的是 Method Call Rule，里面多了选择上下文信息的操作。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(521),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(522),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"context-sensitive-pointer-analysis-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context-sensitive-pointer-analysis-algorithm"}},[t._v("#")]),t._v(" Context Sensitive Pointer Analysis Algorithm")]),t._v(" "),a("p",[a("img",{attrs:{src:s(523),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(524),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(525),alt:""}})]),t._v(" "),a("p",[t._v("可以看一下和 C.I. Algorithm 的对比，确实只是在 Method Call 的时候多个 Select 操作，已经其他参数的地方上下文的不同。实际上，C.I. 是 C.S. 的特例，即 Select 选择出来的上下文永远为空，所有参数的上下文也为空。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(526),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"context-sensitive-variants"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#context-sensitive-variants"}},[t._v("#")]),t._v(" Context Sensitive Variants")]),t._v(" "),a("p",[a("img",{attrs:{src:s(527),alt:""}})]),t._v(" "),a("p",[t._v("这就涉及到使用什么作为上下文标记了。")]),t._v(" "),a("h4",{attrs:{id:"call-site-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#call-site-sensitivity"}},[t._v("#")]),t._v(" Call-Site Sensitivity")]),t._v(" "),a("p",[t._v("Call-Site Sensitivity 是最朴素的想法，记录 Call-Site 就好了，Call-Site 串联起来不就是 Call Stack 么。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(528),alt:""}})]),t._v(" "),a("p",[t._v("但 Call-Site Sensitivity 存在着一定的问题，比如无法处理递归调用。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(529),alt:""}})]),t._v(" "),a("p",[t._v("容易想到可以通过限制 call chain 的长度来解决递归调用时 call chain 无法终止的问题，如下图所示：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(530),alt:""}})]),t._v(" "),a("p",[t._v("看一个例子：")]),t._v(" "),a("p",[a("img",{attrs:{src:s(531),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(532),alt:""}})]),t._v(" "),a("p",[t._v("拿之前 C.I. 的结果进行对比，显然 1-call-site C.S. 的精度要好很多。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(533),alt:""}})]),t._v(" "),a("h4",{attrs:{id:"object-sensitivity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#object-sensitivity"}},[t._v("#")]),t._v(" Object Sensitivity")]),t._v(" "),a("p",[a("img",{attrs:{src:s(534),alt:""}})]),t._v(" "),a("p",[t._v("Call-Site 虽然实现简单也容易理解，但是在 OOPL 里，object 的链式调用使得 k-CFA 不那么好用，比如下面的例子里 1-call-site 精度要差于 1-object。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(535),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(536),alt:""}})]),t._v(" "),a("p",[t._v("但也并不能说明 Ojbect Sensitivity 要比 Call-Site Sensitivity 要好，比如下面的例子中，1-call-site 就比 1-object 精度要好。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(537),alt:""}})]),t._v(" "),a("p",[t._v("实际上，可以发现，在 OOPL 里，Object Sensitivity 中使用 object 作为 Context 可以穿透调用链，使得 k-object 的 'k' 比实际要大得多。")]),t._v(" "),a("h4",{attrs:{id:"object-sensitivity-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#object-sensitivity-2"}},[t._v("#")]),t._v(" Object Sensitivity")]),t._v(" "),a("p",[a("img",{attrs:{src:s(538),alt:""}})]),t._v(" "),a("h4",{attrs:{id:"summary-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#summary-2"}},[t._v("#")]),t._v(" Summary")]),t._v(" "),a("p",[a("img",{attrs:{src:s(539),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec13-static-analysis-for-security"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec13-static-analysis-for-security"}},[t._v("#")]),t._v(" Lec13 Static Analysis for Security")]),t._v(" "),a("p",[t._v("主要讲了污点分析，但感觉和前面大差不差啊，留着后面整理吧。")]),t._v(" "),a("h2",{attrs:{id:"lec14-datalog-based-programming-language"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec14-datalog-based-programming-language"}},[t._v("#")]),t._v(" Lec14 Datalog-Based Programming Language")]),t._v(" "),a("p",[t._v("Datalog 是声明式逻辑语言，当然和 SQL 一样似乎只是一个标准，其实现各有不同。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(540),alt:""}})]),t._v(" "),a("p",[t._v("学了这么多语言，感觉 Datalog 就语法上简单得很啊。就不过多介绍了，直接贴 Datalog 实现的 Pointer Analysis Alogirithm。")]),t._v(" "),a("p",[a("img",{attrs:{src:s(541),alt:""}})]),t._v(" "),a("p",[t._v("当然，Datalog 并非完美的，理由如下：")]),t._v(" "),a("ol",[a("li",[t._v("Datalog 不是图灵完备的，表达能力有限，如 Datalog 里的数据只能增加，无法删除。")]),t._v(" "),a("li",[t._v("Datalog 实际执行是一个黑盒子，看起来简洁的语法背后是执行引擎，这使得将优化的范围缩小了，不利于优化。")])]),t._v(" "),a("h3",{attrs:{id:"introduction-of-datalog"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#introduction-of-datalog"}},[t._v("#")]),t._v(" Introduction of Datalog")]),t._v(" "),a("p",[a("img",{attrs:{src:s(542),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(543),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(544),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(545),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(546),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(547),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"c-i-pointer-analysis-via-datalog"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#c-i-pointer-analysis-via-datalog"}},[t._v("#")]),t._v(" C.I. Pointer Analysis via Datalog")]),t._v(" "),a("p",[a("img",{attrs:{src:s(548),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(549),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(550),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(551),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(552),alt:""}})]),t._v(" "),a("h3",{attrs:{id:"taint-analysis-via-datalog"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#taint-analysis-via-datalog"}},[t._v("#")]),t._v(" Taint Analysis via Datalog")]),t._v(" "),a("p",[a("img",{attrs:{src:s(553),alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:s(554),alt:""}})]),t._v(" "),a("h2",{attrs:{id:"lec15-cfl-reachability-and-ifds"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec15-cfl-reachability-and-ifds"}},[t._v("#")]),t._v(" Lec15 CFL-Reachability and IFDS")]),t._v(" "),a("h2",{attrs:{id:"lec16-soundness-and-soundiness"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lec16-soundness-and-soundiness"}},[t._v("#")]),t._v(" Lec16 Soundness and Soundiness")])])}),[],!1,null,null,null);a.default=n.exports}])]);